{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-Ku4mCaCPR2"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "# from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaDLG4SFCloz"
   },
   "outputs": [],
   "source": [
    "def increase_contrast(image):\n",
    "    # Apply linear contrast stretching\n",
    "    min_val, max_val = np.min(image), np.max(image)\n",
    "    contrast_image = (image - min_val) * (255 / (max_val - min_val))\n",
    "    contrast_image = np.uint8(contrast_image)  # Convert back to uint8 type\n",
    "\n",
    "    return contrast_image\n",
    "def calc_avg_intensity(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def apply_dynamic_threshold(image, avg_intensity):\n",
    "    if (avg_intensity>120 and avg_intensity<130 ): #check if gray compressed (only one that causes issues with threshold is gray compressed)\n",
    "      image = increase_contrast(image)\n",
    "      avg_intensity = calc_avg_intensity(image)\n",
    "\n",
    "    threshold_value = int(avg_intensity * 0.75)\n",
    "    _, thresholded_image = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    return thresholded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJxaNAIFEi0f"
   },
   "outputs": [],
   "source": [
    "def detect_salt_and_pepper_noise(image, black_threshold=20, white_threshold=80):\n",
    "    total_pixels = image.size\n",
    "    black_pixels = np.sum(image == 0)\n",
    "    white_pixels = np.sum(image == 255)\n",
    "\n",
    "    black_ratio = black_pixels / total_pixels * 100\n",
    "    white_ratio = white_pixels / total_pixels * 100\n",
    "\n",
    "    if black_ratio > black_threshold or white_ratio < white_threshold:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAFnuN09C11y"
   },
   "outputs": [],
   "source": [
    "def plot_time_domain(image_path, row=None, col=None):\n",
    "    \"\"\"\n",
    "    Plots the time-domain representation of pixel intensities from an image.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        row (int, optional): Row index to extract pixel intensities. If None, the middle row is used.\n",
    "        col (int, optional): Column index to extract pixel intensities. If None, the middle column is used.\n",
    "    \"\"\"\n",
    "    # Load the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found or unable to load!\")\n",
    "\n",
    "    # Get image dimensions\n",
    "    rows, cols = image.shape\n",
    "\n",
    "    # Determine which row or column to extract\n",
    "    if row is None and col is None:\n",
    "        row = rows // 2  # Default to the middle row\n",
    "    elif row is not None and (row < 0 or row >= rows):\n",
    "        raise ValueError(f\"Row index out of bounds. Must be between 0 and {rows - 1}.\")\n",
    "    elif col is not None and (col < 0 or col >= cols):\n",
    "        raise ValueError(f\"Column index out of bounds. Must be between 0 and {cols - 1}.\")\n",
    "\n",
    "    # Extract the pixel intensities\n",
    "    if row is not None:\n",
    "        intensities = image[row, :]  # Pixel intensities from the row\n",
    "        x = np.arange(cols)  # X-axis: column indices\n",
    "        label = f\"Row {row}\"\n",
    "    else:\n",
    "        intensities = image[:, col]  # Pixel intensities from the column\n",
    "        x = np.arange(rows)  # X-axis: row indices\n",
    "        label = f\"Column {col}\"\n",
    "\n",
    "    # Plot the time-domain representation\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.plot(x, intensities, label=label, color='b')\n",
    "    # plt.title(f\"Time-Domain Representation of {label}\")\n",
    "    # plt.xlabel(\"Pixel Index\")\n",
    "    # plt.ylabel(\"Pixel Intensity\")\n",
    "    # plt.grid()\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "    return intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SpocNSEIC-aI"
   },
   "outputs": [],
   "source": [
    "def analyze_peaks(signal, height=None, distance=50, tolerance=5, sampling_rate=1.0, plot=True):\n",
    "    \"\"\"\n",
    "    Analyzes peaks in the time-domain signal and computes frequency domain characteristics.\n",
    "    Returns the filter type based on the detected dominant frequencies.\n",
    "    \"\"\"\n",
    "    # Dynamically adjust height if not provided\n",
    "    if height is None:\n",
    "        height = np.mean(signal) + 0.5 * np.std(signal)\n",
    "\n",
    "    # Detect peaks\n",
    "    peaks, _ = find_peaks(signal, height=height, distance=distance)\n",
    "\n",
    "    if len(peaks) == 0:\n",
    "        print(\n",
    "            \"No peaks detected. Consider adjusting the 'height' or 'distance' parameters.\")\n",
    "        return {\n",
    "            'peaks': [],\n",
    "            'peak_distances': [],\n",
    "            'are_distances_equal': False,\n",
    "            'dominant_frequencies': [],\n",
    "            'magnitudes': [],\n",
    "            'filter_type': None  # No filter type if no peaks are detected\n",
    "        }\n",
    "\n",
    "    # Calculate peak distances\n",
    "    peak_distances = np.diff(peaks)\n",
    "    if len(peak_distances) > 0:\n",
    "        are_distances_equal = np.allclose(peak_distances, peak_distances[0], atol=tolerance)\n",
    "    else:\n",
    "        are_distances_equal = False\n",
    "\n",
    "    # Compute FFT\n",
    "    fft_result = np.fft.fft(signal)\n",
    "    fft_magnitude = np.abs(fft_result)\n",
    "    fft_frequencies = np.fft.fftfreq(len(signal), d=1/sampling_rate)\n",
    "\n",
    "    # Consider positive frequencies\n",
    "    positive_frequencies = fft_frequencies[:len(signal)//2]\n",
    "    positive_magnitude = fft_magnitude[:len(signal)//2]\n",
    "\n",
    "    # Detect peaks in FFT magnitude\n",
    "    fft_peaks, _ = find_peaks(\n",
    "        positive_magnitude, height=np.mean(positive_magnitude))\n",
    "    dominant_frequencies = positive_frequencies[fft_peaks]\n",
    "    dominant_magnitudes = positive_magnitude[fft_peaks]\n",
    "\n",
    "    # Print the detected dominant frequencies and their magnitudes\n",
    "    # print(\"Detected Dominant Frequencies (Hz):\", dominant_frequencies * 10000)\n",
    "    # print(\"Corresponding Magnitudes:\", dominant_magnitudes)\n",
    "\n",
    "    filter_type = None  # Default filter type is None\n",
    "\n",
    "    # Determine the filter type based on the dominant frequencies\n",
    "    if dominant_frequencies.size > 0:\n",
    "        if dominant_frequencies[0] * 10000 < 60:\n",
    "            filter_type = \"Low-pass\"\n",
    "            # print(\"Low Frequency: Low-pass filter likely used.\")\n",
    "        else:\n",
    "            filter_type = \"High-pass\"\n",
    "            # print(\"High Frequency: High-pass filter likely used.\")\n",
    "    else:\n",
    "        filter_type = \"Low-pass\"  # Default to low-pass if no dominant frequencies\n",
    "\n",
    "    # Plot the signal and frequency domain if requested\n",
    "    # if plot:\n",
    "    #     plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plot time-domain signal\n",
    "        # plt.subplot(2, 1, 1)\n",
    "        # plt.plot(signal, label='Signal')\n",
    "        # plt.plot(peaks, signal[peaks], 'ro', label='Detected Peaks')\n",
    "        # plt.title('Time-Domain Signal with Peaks')\n",
    "        # plt.xlabel('Sample Index')\n",
    "        # plt.ylabel('Amplitude')\n",
    "        # plt.legend()\n",
    "        # plt.grid()\n",
    "\n",
    "        # # Plot frequency-domain\n",
    "        # plt.subplot(2, 1, 2)\n",
    "        # plt.plot(positive_frequencies, positive_magnitude,\n",
    "        #          label='FFT Magnitude')\n",
    "        # plt.plot(dominant_frequencies, dominant_magnitudes,\n",
    "        #          'ro', label='Dominant Frequencies')\n",
    "        # plt.title('Frequency-Domain Analysis')\n",
    "        # plt.xlabel('Frequency (Hz)')\n",
    "        # plt.ylabel('Magnitude')\n",
    "        # plt.legend()\n",
    "        # plt.grid()\n",
    "\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "    # Return analysis results including the filter type\n",
    "    return {\n",
    "        'peaks': peaks,\n",
    "        'peak_distances': peak_distances,\n",
    "        'are_distances_equal': are_distances_equal,\n",
    "        'dominant_frequencies': dominant_frequencies,\n",
    "        'magnitudes': dominant_magnitudes,\n",
    "        'filter_type': filter_type\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yADUl7i4DEM8"
   },
   "outputs": [],
   "source": [
    "def are_peaks_equally_spaced(signal, height=None, distance=50, tolerance=5):\n",
    "    \"\"\"\n",
    "    Checks if the spaces (differences) between peaks in the given signal are approximately equal.\n",
    "\n",
    "    Parameters:\n",
    "        signal (numpy array): The input time-domain signal (1D array).\n",
    "        height (float): Minimum height for a point to be considered a peak. Default is 150.\n",
    "        distance (int): Minimum distance between consecutive peaks. Default is 50.\n",
    "        tolerance (int): Allowed deviation for equal distances. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the differences between consecutive peaks are approximately equal, False otherwise.\n",
    "    \"\"\"\n",
    "    # Detect peaks\n",
    "    peaks, _ = find_peaks(signal, height=height, distance=distance)\n",
    "\n",
    "    # Calculate peak distances\n",
    "    peak_distances = np.diff(peaks)\n",
    "\n",
    "    # Check if all distances are approximately equal\n",
    "    if len(peak_distances) > 0:\n",
    "        return np.allclose(peak_distances, peak_distances[0], atol=tolerance)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyHGsq4ADK1D"
   },
   "outputs": [],
   "source": [
    "def give_me_circle_mask_nowww(mask_size, radius):\n",
    "    mask = np.zeros(mask_size)\n",
    "    cy = mask.shape[0] // 2\n",
    "    cx = mask.shape[1] // 2\n",
    "    return cv2.circle(mask, (cx, cy), radius, (255, 255, 255), -1).astype(np.uint8)\n",
    "\n",
    "def plot_shifted_fft_and_ifft(dft_img_shifted):\n",
    "    img = np.fft.ifft2(np.fft.ifftshift(dft_img_shifted))\n",
    "    # fig, (ax1, ax2) = plt.subplots(figsize=(10, 5), nrows=1, ncols=2)\n",
    "    # ax1.set(yticks=[0, img.shape[0]//2, img.shape[0] - 1],\n",
    "    #         yticklabels=[-img.shape[0]//2, 0, img.shape[0]//2 - 1])\n",
    "    # ax1.set(xticks=[0, img.shape[1]//2, img.shape[1] - 1],\n",
    "    #         xticklabels=[-img.shape[1]//2, 0, img.shape[1]//2 - 1])\n",
    "    # ax1.imshow(np.abs(dft_img_shifted)**0.1, cmap='gray')\n",
    "    # ax2.imshow(np.abs(img), cmap='gray')\n",
    "\n",
    "    # img = np.abs(img.astype(np.uint16))\n",
    "    img = np.abs(img)  # Get magnitude\n",
    "    img = img.astype(np.uint16)\n",
    "    # plt.imsave(\"AX2.jpg\",img)\n",
    "    # img = cv2.imread(\"AX2.jpg\")\n",
    "    # cv2.imshow(\"AX2\", img)\n",
    "    # ax2 = ax2.astype(np.uint32)\n",
    "    # ax2.imsave(\"Test Cases\\\\11 - bayza 5ales di bsara7a#3.jpg\", np.abs(img), p)\n",
    "    # plt.show()\n",
    "    return img\n",
    "\n",
    "def try_highpass(dft_img, limit, gaussian: bool = False, keep_dc: bool = False):\n",
    "    mask = ~give_me_circle_mask_nowww(dft_img.shape, limit)\n",
    "    if (gaussian):\n",
    "        mask = cv2.GaussianBlur(mask, (21, 21), 0)\n",
    "    if (keep_dc):\n",
    "        mask[dft_img.shape[0]//2, dft_img.shape[1]//2] = 255\n",
    "    dft_img_shifted = np.fft.fftshift(dft_img)\n",
    "    dft_img_shifted_highpass = np.multiply(dft_img_shifted, mask)\n",
    "    freqimg = plot_shifted_fft_and_ifft(dft_img_shifted_highpass)\n",
    "    return freqimg\n",
    "\n",
    "\n",
    "def try_lowpass(dft_img, limit, gaussian: bool = False):\n",
    "    mask = give_me_circle_mask_nowww(dft_img.shape, limit)\n",
    "    if (gaussian):\n",
    "        mask = cv2.GaussianBlur(mask, (21, 21), 0)\n",
    "    dft_img_shifted = np.fft.fftshift(dft_img)\n",
    "    dft_img_shifted_lowpass = np.multiply(dft_img_shifted, mask)\n",
    "    freqimg = plot_shifted_fft_and_ifft(dft_img_shifted_lowpass)\n",
    "    return freqimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_normalize_bar_sizes(pixels, narrow_bar_size, wide_bar_size,):\n",
    "    bar_widths = []\n",
    "    current_width = 1\n",
    "    current_pixel = pixels[0]\n",
    "\n",
    "    for pixel in pixels[1:]:\n",
    "        if pixel == current_pixel:\n",
    "            current_width += 1\n",
    "            # print(f\"current pixel is : {current_pixel}\")\n",
    "        else:\n",
    "            bar_widths.append((current_pixel, current_width))\n",
    "            # print(f\"current width is : {current_width}\")\n",
    "            current_width = 1\n",
    "            current_pixel = pixel\n",
    "\n",
    "    if current_width > 0:\n",
    "        bar_widths.append((current_pixel, current_width))\n",
    "\n",
    "    # narrow_bar_size = min(width for _, width in bar_widths)\n",
    "    # wide_bar_size = 2* narrow_bar_size\n",
    "    # max_bar_size = max(width for _, width in bar_widths if width > narrow_bar_size)\n",
    "    average = sum(width for _, width in bar_widths) / len(bar_widths)\n",
    "    # print(f\"average is {average}\")\n",
    "    normalized_pixels = []\n",
    "\n",
    "    for pixel, width in bar_widths:\n",
    "        if width <= narrow_bar_size:\n",
    "            normalized_pixels.append((pixel, narrow_bar_size))\n",
    "        elif width > narrow_bar_size:\n",
    "            if width <= average:\n",
    "                normalized_pixels.append((pixel, narrow_bar_size))\n",
    "            elif average < width:\n",
    "                normalized_pixels.extend([(pixel, wide_bar_size)])\n",
    "            else:\n",
    "                print(\"Invalid barcode\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Invalid barcode\")\n",
    "            break\n",
    "\n",
    "    normalized_pixel_str = ''.join(\n",
    "        ('1' * width) if pixel == '1' else ('0' * width) for pixel, width in normalized_pixels)\n",
    "\n",
    "    return normalized_pixel_str\n",
    "\n",
    "\n",
    "def decode_barcode():\n",
    "    # 0 means narrow, 1 means wide\n",
    "    NARROW = \"0\"\n",
    "    WIDE = \"1\"\n",
    "    code11_widths = {\n",
    "        \"00110\": \"Stop/Start\",\n",
    "        \"10001\": \"1\",\n",
    "        \"01001\": \"2\",\n",
    "        \"11000\": \"3\",\n",
    "        \"00101\": \"4\",\n",
    "        \"10100\": \"5\",\n",
    "        \"01100\": \"6\",\n",
    "        \"00011\": \"7\",\n",
    "        \"10010\": \"8\",\n",
    "        \"10000\": \"9\",\n",
    "        \"00001\": \"0\",\n",
    "        \"00100\": \"-\",\n",
    "    }\n",
    "    img = cv2.imread(\"FinalImage.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    # Get the average of each column in your image\n",
    "    mean = img.mean(axis=0)\n",
    "    # print(mean)\n",
    "    # Set it to black or white based on its value\n",
    "    mean[mean <= 127] = 1\n",
    "    mean[mean > 128] = 0\n",
    "    # Convert to string of pixels in order to loop over it\n",
    "    pixels = ''.join(mean.astype(np.uint8).astype(str))\n",
    "    # print(pixels)\n",
    "\n",
    "    # Need to figure out how many pixels represent a narrow bar\n",
    "    narrow_bar_size = 0\n",
    "    for pixel in pixels:\n",
    "        if pixel == \"1\":\n",
    "            narrow_bar_size += 1\n",
    "            # print(narrow_bar_size)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    wide_bar_size = narrow_bar_size * 2\n",
    "\n",
    "    # print(f\"Detected narrow bar size: {narrow_bar_size}\")\n",
    "    # print(f\"Detected wide bar size: {wide_bar_size}\")\n",
    "\n",
    "    pixels = detect_and_normalize_bar_sizes(\n",
    "        pixels, narrow_bar_size, wide_bar_size)\n",
    "    # print(f\"Detected pixels: {pixels}\")\n",
    "\n",
    "    digits = []\n",
    "    pixel_index = 0\n",
    "    current_digit_widths = \"\"\n",
    "    skip_next = False\n",
    "    while pixel_index < len(pixels):\n",
    "\n",
    "        if skip_next:\n",
    "            pixel_index += narrow_bar_size\n",
    "            skip_next = False\n",
    "            continue\n",
    "        count = 1\n",
    "        try:                                                      # 1 1 1 1 0 0 0 0 1 1 1  1  1  1  1  1\n",
    "                                                                  # 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
    "            while pixels[pixel_index] == pixels[pixel_index + 1]:\n",
    "                count += 1\n",
    "                pixel_index += 1\n",
    "        except:\n",
    "            pass\n",
    "        pixel_index += 1\n",
    "        current_digit_widths += NARROW if count == narrow_bar_size else WIDE\n",
    "        # print(current_digit_widths)\n",
    "        if current_digit_widths in code11_widths:\n",
    "            digits.append(code11_widths[current_digit_widths])\n",
    "            current_digit_widths = \"\"\n",
    "            skip_next = True  # Next iteration will be a separator, so skip it\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Detected barcode is:\")\n",
    "    print(\"--------------------\")\n",
    "    print(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joVQt6IKDYZW"
   },
   "outputs": [],
   "source": [
    "def remove_initial_whites(pixels):\n",
    "    first_black_index = pixels.find('1')\n",
    "    if first_black_index == -1:\n",
    "        return \"\", 0\n",
    "    return pixels[first_black_index:] ,first_black_index\n",
    "\n",
    "\n",
    "def make_columns_uniform(image):\n",
    "    height, width = image.shape\n",
    "    num_parts = 10\n",
    "    part_height = height // num_parts\n",
    "\n",
    "    for x in range(width):\n",
    "        part_most_common = []\n",
    "\n",
    "        for part in range(num_parts):\n",
    "            start_idx = part * part_height\n",
    "            end_idx = (part + 1) * part_height if part != num_parts - 1 else height\n",
    "            part_pixels = image[start_idx:end_idx, x]\n",
    "\n",
    "            # Find  most common pixel value in the part\n",
    "            unique, counts = np.unique(part_pixels, return_counts=True)\n",
    "\n",
    "            for idx, item in enumerate(unique):\n",
    "                if item >= 128:\n",
    "                    unique[idx] = 255\n",
    "                else:\n",
    "                    unique[idx] = 0\n",
    "\n",
    "            mode_pixel = unique[np.argmax(counts)]\n",
    "            part_most_common.append(mode_pixel)\n",
    "\n",
    "        # Determine the most common value among the parts\n",
    "        final_unique, final_counts = np.unique(part_most_common, return_counts=True)\n",
    "        most_common_pixel = final_unique[np.argmax(final_counts)]\n",
    "\n",
    "        # Set all pixels in the column to the most common value\n",
    "        image[:, x] = most_common_pixel\n",
    "\n",
    "\n",
    "    return image\n",
    "\n",
    "# This function reorder the corners points appropriatly\n",
    "# Helped significantly with warp function\n",
    "def reorder(myPoints):\n",
    "    myPoints = myPoints.reshape((4, 2))\n",
    "    myPointsNew = np.zeros((4, 1, 2), dtype=np.int32)\n",
    "    add = myPoints.sum(1)\n",
    "    myPointsNew[1] = myPoints[np.argmin(add)]\n",
    "    myPointsNew[3] = myPoints[np.argmax(add)]\n",
    "    diff = np.diff(myPoints, axis=1)\n",
    "    myPointsNew[0] = myPoints[np.argmin(diff)]\n",
    "    myPointsNew[2] = myPoints[np.argmax(diff)]\n",
    "    return myPointsNew\n",
    "\n",
    "def detect_barcode(image):\n",
    "\n",
    "\n",
    "\n",
    "    # blur before sobel\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5),0)\n",
    "    # compute the Scharr gradient magnitude representation of the images in both the x and y direction\n",
    "    gradX = cv2.Sobel(blurred, ddepth = cv2.CV_32F, dx = 1, dy = 0, ksize = -1)\n",
    "    gradY = cv2.Sobel(blurred, ddepth = cv2.CV_32F, dx = 0, dy = 1, ksize = -1)\n",
    "\n",
    "\n",
    "\n",
    "    # subtract the y-gradient from the x-gradient\n",
    "    gradient = cv2.subtract(gradX, gradY)\n",
    "    gradient = cv2.convertScaleAbs(gradient)\n",
    "    # blur and threshold the image\n",
    "    blurred = cv2.blur(gradient, (9, 9))\n",
    "    (_, thresh) = cv2.threshold(blurred, 225, 255, cv2.THRESH_BINARY)\n",
    "    # cv2.imshow(\"thresholded\",thresh)\n",
    "\n",
    "\n",
    "    # construct a closing kernel and apply it to the thresholded image\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (21, 7))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # perform a series of erosions and dilations\n",
    "    # cv2.imshow('closed1', closed)\n",
    "    closed = cv2.erode(closed, None, iterations = 4)\n",
    "\n",
    "    closed = cv2.dilate(closed, None, iterations = 4)\n",
    "\n",
    "    # find the contours in the thresholded image,\n",
    "    #  then sort the contours by their area,\n",
    "    #  keeping only the largest one\n",
    "    (cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "\n",
    "    if cv2.contourArea(cnt) > 0:  # Check if contour is valid\n",
    "\n",
    "        # compute the rotated bounding box of the largest contour\n",
    "        rect = cv2.minAreaRect(cnt)\n",
    "        box = np.int32(cv2.boxPoints(rect))\n",
    "        box = reorder(box)\n",
    "\n",
    "\n",
    "        # Coordinates of each corner\n",
    "        ax = box.item(0)\n",
    "        ay = box.item(1)\n",
    "\n",
    "        bx = box.item(2)\n",
    "        by = box.item(3)\n",
    "\n",
    "        cx = box.item(4)\n",
    "        cy = box.item(5)\n",
    "\n",
    "        dx = box.item(6)\n",
    "        dy = box.item(7)\n",
    "\n",
    "        widthA = np.sqrt(((cx - dx) ** 2) + ((cy - dy) ** 2))\n",
    "        widthB = np.sqrt(((ax - bx) ** 2) + ((ay - by) ** 2))\n",
    "        width = max(int(widthA), int(widthB))\n",
    "\n",
    "        heightA = np.sqrt(((ax - dx) ** 2) + ((ay - dy) ** 2))\n",
    "        heightB = np.sqrt(((bx - cx) ** 2) + ((by - cy) ** 2))\n",
    "        height = max(int(heightA), int(heightB))\n",
    "\n",
    "\n",
    "        pts1 = np.float32([[bx, by], [ax, ay], [cx, cy], [dx, dy]])\n",
    "        pts2 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "        matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "        img_prespective = cv2.warpPerspective(image, matrix, (width, height))\n",
    "\n",
    "\n",
    "        uniform_image = make_columns_uniform(img_prespective)\n",
    "\n",
    "        cv2.imwrite(\"UniformImage.jpg\", uniform_image)\n",
    "        img = cv2.imread(\"UniformImage.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "        # Get the average of each column in your image\n",
    "        mean = img.mean(axis=0)\n",
    "\n",
    "        # Set it to black or white based on its value\n",
    "        mean[mean <= 127] = 1\n",
    "        mean[mean > 128] = 0\n",
    "        # Convert to string of pixels in order to loop over it\n",
    "        pixels = ''.join(mean.astype(np.uint8).astype(str))\n",
    "        pixels , ignore= remove_initial_whites(pixels)\n",
    "        image_modified = img[ignore:, ignore:]\n",
    "        cv2.imwrite(\"FinalImage.jpg\", image_modified)\n",
    "        plt.imshow(image_modified, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        # cv2.imshow(\"Final Image\", image_modified)\n",
    "        decoded_digits = decode_barcode()\n",
    "        print(decoded_digits)\n",
    "        cv2.waitKey(0)\n",
    "    else:\n",
    "        print(\"No barcode detected\")\n",
    "        cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9f_3q1oEN41"
   },
   "outputs": [],
   "source": [
    "def preprocessing(img , image_path):\n",
    "\n",
    "    avg_intensity =calc_avg_intensity(img)\n",
    "    thresh = apply_dynamic_threshold(img, avg_intensity)\n",
    "    is_salt_pepper =detect_salt_and_pepper_noise(thresh)\n",
    "\n",
    "    print(img.shape)\n",
    "    print(\"Is Salt and Peper Noise ?\",is_salt_pepper)\n",
    "    if is_salt_pepper:\n",
    "        intensities =plot_time_domain(image_path,300,300)\n",
    "        print(is_salt_pepper)\n",
    "        # Call the function\n",
    "        results = analyze_peaks(intensities, height=150, distance=50, tolerance=5)\n",
    "        peaks_equally_spaced = are_peaks_equally_spaced(intensities,height = 150)\n",
    "        # Output results\n",
    "        # print(\"Peak indices:\", results['peaks'])\n",
    "        # print(\"Peak distances:\", results['peak_distances'])\n",
    "        # print(\"Are distances approximately equal?\", results['are_distances_equal'])\n",
    "\n",
    "\n",
    "        if peaks_equally_spaced:\n",
    "            # avg_int2 = calc_avg_intensity(img)\n",
    "            dft_img = np.fft.fft2(img)\n",
    "            # dft_img_shift = np.fft.fftshift(dft_img)\n",
    "            if results['filter_type'] == \"High-pass\":\n",
    "                freqimg = try_highpass(dft_img, 20, gaussian=False, keep_dc=True)\n",
    "                # If try_highpass produces complex numbers, extract magnitude\n",
    "                freqimg = np.abs(freqimg)\n",
    "                # Ensure the image is in a uint8 format (0-255) for OpenCV compatibility\n",
    "                freqimg = np.uint8(255 * (freqimg / np.max(freqimg)))  # Normalize to 0-255\n",
    "                # If needed, ensure single-channel image\n",
    "                if len(freqimg.shape) > 2:\n",
    "                    freqimg = cv2.cvtColor(freqimg, cv2.COLOR_BGR2GRAY)\n",
    "                contrast =increase_contrast(freqimg)\n",
    "                detect_barcode(contrast)\n",
    "                plt.show(freqimg, cmap='gray')\n",
    "                # cv2.imshow(\"Frequency Domain\", freqimg)\n",
    "\n",
    "            elif results['filter_type'] == \"Low-pass\":\n",
    "                freqimg = try_lowpass(dft_img, 150, gaussian=True)\n",
    "                # If try_highpass produces complex numbers, extract magnitude\n",
    "                freqimg = np.abs(freqimg)\n",
    "                # Ensure the image is in a uint8 format (0-255) for OpenCV compatibility\n",
    "                # Normalize to 0-255\n",
    "                freqimg = np.uint8(255 * (freqimg / np.max(freqimg)))\n",
    "                # If needed, ensure single-channel image\n",
    "                if len(freqimg.shape) > 2:\n",
    "                    freqimg = cv2.cvtColor(freqimg, cv2.COLOR_BGR2GRAY)\n",
    "                contrast = increase_contrast(freqimg)\n",
    "                detect_barcode(contrast)\n",
    "                plt.show(freqimg, cmap='gray')\n",
    "\n",
    "                # plt.show(freqimg, cmap='gray')\n",
    "\n",
    "                # cv2.imshow(\"Frequency Domain\", freqimg)\n",
    "        else:\n",
    "            avg_intensity =calc_avg_intensity(img)\n",
    "            thresholded_image = apply_dynamic_threshold(img,avg_intensity)\n",
    "            # cv2.imshow(\"Thresholded Image\", thresholded_image)\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            dil_img = cv2.dilate(thresholded_image, kernel, iterations=1)\n",
    "            erode_img = cv2.erode(dil_img, kernel, iterations=1)\n",
    "\n",
    "            # cv2.imshow(\"Dilated Image\", erode_img)\n",
    "            detect_barcode(erode_img)\n",
    "    else:\n",
    "        print(\"No Salt and Pepper Noise\")\n",
    "\n",
    "        avg_intensity =calc_avg_intensity(img)\n",
    "        brightness_threshold = 250\n",
    "\n",
    "        if avg_intensity < brightness_threshold:\n",
    "            thresholded_image = apply_dynamic_threshold(img,avg_intensity)\n",
    "            # cv2.imshow(\"Thresholded Image\", thresholded_image)\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            dil_img = cv2.dilate(thresholded_image, kernel, iterations=1)\n",
    "            erode_img = cv2.erode(dil_img, kernel, iterations=1)\n",
    "            result =increase_contrast(erode_img)\n",
    "            detect_barcode(result)\n",
    "        else:\n",
    "            result =increase_contrast(img)\n",
    "            detect_barcode(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "USNUVEM1ElUL",
    "outputId": "2d41de90-b0aa-4cd6-ed59-94b34064826a"
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------MAIN--------------------------------\n",
    "# Uncomment the needed Test Case\n",
    "\n",
    "# image_path =\" Test Cases/01 - lol easy.jpg\" #Done\n",
    "# image_path =\" Test Cases/02 - still easy.jpg\" #Done\n",
    "# image_path =\" Test Cases/03 - eda ya3am ew3a soba3ak mathazarsh.jpg\" #Done\n",
    "# image_path =\" Test Cases/04 - fen el nadara.jpg\" #Decoder Can't detect the barcode\n",
    "# image_path =\" Test Cases/05 - meen taffa el nour!!!.jpg\" #Decoder Can't detect the barcode\n",
    "# image_path =\" Test Cases/06 - meen fata7 el nour 333eenaaayy.jpg\" #Decoder Can't detect the barcode\n",
    "# image_path =\" Test Cases/07 - mal7 w felfel.jpg\" #Decoder Can't detect the barcode\n",
    "# image_path =\" Test Cases/08 - compresso espresso.jpg\" #Decoder Can't detect the barcode\n",
    "# image_path =\" Test Cases/09 - e3del el soora ya3ammm.jpg\" #Decoder Can't detect the barcode\n",
    "# image_path =\" Test Cases/10 - wen el kontraastttt.jpg\" #Decoder Can't detect the barcode\n",
    "image_path ='Test Cases/11 - bayza 5ales di bsara7a.jpg' #Decoder Can't detect the barcode\n",
    "\n",
    "img = cv2.imread(image_path, 0)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "# cv2.imshow(\"Original Image\", img)\n",
    "preprocessing(img, image_path)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
