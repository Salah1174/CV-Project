{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "E-Ku4mCaCPR2"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "# from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "gaDLG4SFCloz"
   },
   "outputs": [],
   "source": [
    "def increase_contrast(image):\n",
    "    # Apply linear contrast stretching\n",
    "    min_val, max_val = np.min(image), np.max(image)\n",
    "    contrast_image = (image - min_val) * (255 / (max_val - min_val))\n",
    "    contrast_image = np.uint8(contrast_image)  # Convert back to uint8 type\n",
    "\n",
    "    return contrast_image\n",
    "def calc_avg_intensity(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def apply_dynamic_threshold(image, avg_intensity):\n",
    "    if (avg_intensity>120 and avg_intensity<130 ): #check if gray compressed (only one that causes issues with threshold is gray compressed)\n",
    "      image = increase_contrast(image)\n",
    "      avg_intensity = calc_avg_intensity(image)\n",
    "\n",
    "    threshold_value = int(avg_intensity * 0.75)\n",
    "    _, thresholded_image = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    return thresholded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "fJxaNAIFEi0f"
   },
   "outputs": [],
   "source": [
    "def detect_salt_and_pepper_noise(image, black_threshold=20, white_threshold=80):\n",
    "    total_pixels = image.size\n",
    "    black_pixels = np.sum(image == 0)\n",
    "    white_pixels = np.sum(image == 255)\n",
    "\n",
    "    black_ratio = black_pixels / total_pixels * 100\n",
    "    white_ratio = white_pixels / total_pixels * 100\n",
    "\n",
    "    if black_ratio > black_threshold or white_ratio < white_threshold:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "OAFnuN09C11y"
   },
   "outputs": [],
   "source": [
    "def plot_time_domain(image_path, row=None, col=None):\n",
    "    \"\"\"\n",
    "    Plots the time-domain representation of pixel intensities from an image.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        row (int, optional): Row index to extract pixel intensities. If None, the middle row is used.\n",
    "        col (int, optional): Column index to extract pixel intensities. If None, the middle column is used.\n",
    "    \"\"\"\n",
    "    # Load the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found or unable to load!\")\n",
    "\n",
    "    # Get image dimensions\n",
    "    rows, cols = image.shape\n",
    "\n",
    "    # Determine which row or column to extract\n",
    "    if row is None and col is None:\n",
    "        row = rows // 2  # Default to the middle row\n",
    "    elif row is not None and (row < 0 or row >= rows):\n",
    "        raise ValueError(f\"Row index out of bounds. Must be between 0 and {rows - 1}.\")\n",
    "    elif col is not None and (col < 0 or col >= cols):\n",
    "        raise ValueError(f\"Column index out of bounds. Must be between 0 and {cols - 1}.\")\n",
    "\n",
    "    # Extract the pixel intensities\n",
    "    if row is not None:\n",
    "        intensities = image[row, :]  # Pixel intensities from the row\n",
    "        x = np.arange(cols)  # X-axis: column indices\n",
    "        label = f\"Row {row}\"\n",
    "    else:\n",
    "        intensities = image[:, col]  # Pixel intensities from the column\n",
    "        x = np.arange(rows)  # X-axis: row indices\n",
    "        label = f\"Column {col}\"\n",
    "\n",
    "\n",
    "    return intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "SpocNSEIC-aI"
   },
   "outputs": [],
   "source": [
    "def analyze_peaks(signal, height=None, distance=50, tolerance=5, sampling_rate=1.0, plot=True):\n",
    "    \"\"\"\n",
    "    Analyzes peaks in the time-domain signal and computes frequency domain characteristics.\n",
    "    Returns the filter type based on the detected dominant frequencies.\n",
    "    \"\"\"\n",
    "    # Dynamically adjust height if not provided\n",
    "    if height is None:\n",
    "        height = np.mean(signal) + 0.5 * np.std(signal)\n",
    "\n",
    "    # Detect peaks\n",
    "    peaks, _ = find_peaks(signal, height=height, distance=distance)\n",
    "\n",
    "    if len(peaks) == 0:\n",
    "        print(\n",
    "            \"No peaks detected. Consider adjusting the 'height' or 'distance' parameters.\")\n",
    "        return {\n",
    "            'peaks': [],\n",
    "            'peak_distances': [],\n",
    "            'are_distances_equal': False,\n",
    "            'dominant_frequencies': [],\n",
    "            'magnitudes': [],\n",
    "            'filter_type': None  # No filter type if no peaks are detected\n",
    "        }\n",
    "\n",
    "    # Calculate peak distances\n",
    "    peak_distances = np.diff(peaks)\n",
    "    if len(peak_distances) > 0:\n",
    "        are_distances_equal = np.allclose(peak_distances, peak_distances[0], atol=tolerance)\n",
    "    else:\n",
    "        are_distances_equal = False\n",
    "\n",
    "    # Compute FFT\n",
    "    fft_result = np.fft.fft(signal)\n",
    "    fft_magnitude = np.abs(fft_result)\n",
    "    fft_frequencies = np.fft.fftfreq(len(signal), d=1/sampling_rate)\n",
    "\n",
    "    # Consider positive frequencies\n",
    "    positive_frequencies = fft_frequencies[:len(signal)//2]\n",
    "    positive_magnitude = fft_magnitude[:len(signal)//2]\n",
    "\n",
    "    # Detect peaks in FFT magnitude\n",
    "    fft_peaks, _ = find_peaks(\n",
    "        positive_magnitude, height=np.mean(positive_magnitude))\n",
    "    dominant_frequencies = positive_frequencies[fft_peaks]\n",
    "    dominant_magnitudes = positive_magnitude[fft_peaks]\n",
    "\n",
    "\n",
    "    filter_type = None  # Default filter type is None\n",
    "\n",
    "    # Determine the filter type based on the dominant frequencies\n",
    "    if dominant_frequencies.size > 0:\n",
    "        if dominant_frequencies[0] * 10000 < 60:\n",
    "            filter_type = \"Low-pass\"\n",
    "            # print(\"Low Frequency: Low-pass filter likely used.\")\n",
    "        else:\n",
    "            filter_type = \"High-pass\"\n",
    "            # print(\"High Frequency: High-pass filter likely used.\")\n",
    "    else:\n",
    "        filter_type = \"Low-pass\"  # Default to low-pass if no dominant frequencies\n",
    "\n",
    "    # Return analysis results including the filter type\n",
    "    return {\n",
    "        'peaks': peaks,\n",
    "        'peak_distances': peak_distances,\n",
    "        'are_distances_equal': are_distances_equal,\n",
    "        'dominant_frequencies': dominant_frequencies,\n",
    "        'magnitudes': dominant_magnitudes,\n",
    "        'filter_type': filter_type\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "yADUl7i4DEM8"
   },
   "outputs": [],
   "source": [
    "def are_peaks_equally_spaced(signal, height=None, distance=50, tolerance=5):\n",
    "    \"\"\"\n",
    "    Checks if the spaces (differences) between peaks in the given signal are approximately equal.\n",
    "\n",
    "    Parameters:\n",
    "        signal (numpy array): The input time-domain signal (1D array).\n",
    "        height (float): Minimum height for a point to be considered a peak. Default is 150.\n",
    "        distance (int): Minimum distance between consecutive peaks. Default is 50.\n",
    "        tolerance (int): Allowed deviation for equal distances. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the differences between consecutive peaks are approximately equal, False otherwise.\n",
    "    \"\"\"\n",
    "    # Detect peaks\n",
    "    peaks, _ = find_peaks(signal, height=height, distance=distance)\n",
    "\n",
    "    # Calculate peak distances\n",
    "    peak_distances = np.diff(peaks)\n",
    "\n",
    "    # Check if all distances are approximately equal\n",
    "    if len(peak_distances) > 0:\n",
    "        return np.allclose(peak_distances, peak_distances[0], atol=tolerance)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "vyHGsq4ADK1D"
   },
   "outputs": [],
   "source": [
    "def give_me_circle_mask_nowww(mask_size, radius):\n",
    "    mask = np.zeros(mask_size)\n",
    "    cy = mask.shape[0] // 2\n",
    "    cx = mask.shape[1] // 2\n",
    "    return cv2.circle(mask, (cx, cy), radius, (255, 255, 255), -1).astype(np.uint8)\n",
    "\n",
    "def plot_shifted_fft_and_ifft(dft_img_shifted):\n",
    "    img = np.fft.ifft2(np.fft.ifftshift(dft_img_shifted))\n",
    "    img = np.abs(img)  # Get magnitude\n",
    "    img = img.astype(np.uint16)\n",
    "    return img\n",
    "\n",
    "def try_highpass(dft_img, limit, gaussian: bool = False, keep_dc: bool = False):\n",
    "    mask = ~give_me_circle_mask_nowww(dft_img.shape, limit)\n",
    "    if (gaussian):\n",
    "        mask = cv2.GaussianBlur(mask, (21, 21), 0)\n",
    "    if (keep_dc):\n",
    "        mask[dft_img.shape[0]//2, dft_img.shape[1]//2] = 255\n",
    "    dft_img_shifted = np.fft.fftshift(dft_img)\n",
    "    dft_img_shifted_highpass = np.multiply(dft_img_shifted, mask)\n",
    "    freqimg = plot_shifted_fft_and_ifft(dft_img_shifted_highpass)\n",
    "    return freqimg\n",
    "\n",
    "\n",
    "def try_lowpass(dft_img, limit, gaussian: bool = False):\n",
    "    mask = give_me_circle_mask_nowww(dft_img.shape, limit)\n",
    "    if (gaussian):\n",
    "        mask = cv2.GaussianBlur(mask, (21, 21), 0)\n",
    "    dft_img_shifted = np.fft.fftshift(dft_img)\n",
    "    dft_img_shifted_lowpass = np.multiply(dft_img_shifted, mask)\n",
    "    freqimg = plot_shifted_fft_and_ifft(dft_img_shifted_lowpass)\n",
    "    return freqimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_normalize_bar_sizes(pixels, narrow_bar_size, wide_bar_size,):\n",
    "    bar_widths = []\n",
    "    current_width = 1\n",
    "    current_pixel = pixels[0]\n",
    "    # loop through the pixels and count the width of each bar\n",
    "    for pixel in pixels[1:]:\n",
    "        if pixel == current_pixel:\n",
    "            current_width += 1\n",
    "        else:\n",
    "            bar_widths.append((current_pixel, current_width))\n",
    "            current_width = 1\n",
    "            current_pixel = pixel\n",
    "\n",
    "    if current_width > 0:\n",
    "        bar_widths.append((current_pixel, current_width))\n",
    "\n",
    "    # calculate average width of the bars\n",
    "    average = sum(width for _, width in bar_widths) / len(bar_widths)\n",
    "    normalized_pixels = []\n",
    "    # loop through the bar widths and normalize them\n",
    "    for pixel, width in bar_widths:\n",
    "        if width <= narrow_bar_size:\n",
    "            normalized_pixels.append((pixel, narrow_bar_size))\n",
    "        elif width > narrow_bar_size:\n",
    "            if width <= average:\n",
    "                normalized_pixels.append((pixel, narrow_bar_size))\n",
    "            elif average < width:\n",
    "                normalized_pixels.extend([(pixel, wide_bar_size)])\n",
    "            else:\n",
    "                print(\"Invalid barcode\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Invalid barcode\")\n",
    "            break\n",
    "    # convert the normalized pixels to a string\n",
    "    normalized_pixel_str = ''.join(\n",
    "        ('1' * width) if pixel == '1' else ('0' * width) for pixel, width in normalized_pixels)\n",
    "\n",
    "    return normalized_pixel_str\n",
    "\n",
    "\n",
    "def decode_barcode():\n",
    "    # 0 means narrow, 1 means wide\n",
    "    NARROW = \"0\"\n",
    "    WIDE = \"1\"\n",
    "    code11_widths = {\n",
    "        \"00110\": \"Stop/Start\",\n",
    "        \"10001\": \"1\",\n",
    "        \"01001\": \"2\",\n",
    "        \"11000\": \"3\",\n",
    "        \"00101\": \"4\",\n",
    "        \"10100\": \"5\",\n",
    "        \"01100\": \"6\",\n",
    "        \"00011\": \"7\",\n",
    "        \"10010\": \"8\",\n",
    "        \"10000\": \"9\",\n",
    "        \"00001\": \"0\",\n",
    "        \"00100\": \"-\",\n",
    "    }\n",
    "    img = cv2.imread(\"FinalImage.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    # Get the average of each column in your image\n",
    "    mean = img.mean(axis=0)\n",
    "    # Set it to black or white based on its value\n",
    "    mean[mean <= 127] = 1\n",
    "    mean[mean > 128] = 0\n",
    "    # Convert to string of pixels in order to loop over it\n",
    "    pixels = ''.join(mean.astype(np.uint8).astype(str))\n",
    "\n",
    "    # Need to figure out how many pixels represent a narrow bar\n",
    "    narrow_bar_size = 0\n",
    "    for pixel in pixels:\n",
    "        if pixel == \"1\":\n",
    "            narrow_bar_size += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    wide_bar_size = narrow_bar_size * 2\n",
    "\n",
    "    # Normalize the bar sizes\n",
    "    pixels = detect_and_normalize_bar_sizes(\n",
    "        pixels, narrow_bar_size, wide_bar_size)\n",
    "\n",
    "    digits = []\n",
    "    pixel_index = 0\n",
    "    current_digit_widths = \"\"\n",
    "    skip_next = False\n",
    "    while pixel_index < len(pixels):\n",
    "\n",
    "        if skip_next:\n",
    "            pixel_index += narrow_bar_size\n",
    "            skip_next = False\n",
    "            continue\n",
    "        count = 1\n",
    "        try:                                                    \n",
    "            while pixels[pixel_index] == pixels[pixel_index + 1]:\n",
    "                count += 1\n",
    "                pixel_index += 1\n",
    "        except:\n",
    "            pass\n",
    "        pixel_index += 1\n",
    "        current_digit_widths += NARROW if count == narrow_bar_size else WIDE\n",
    "        if current_digit_widths in code11_widths:\n",
    "            digits.append(code11_widths[current_digit_widths])\n",
    "            current_digit_widths = \"\"\n",
    "            skip_next = True  # Next iteration will be a separator, so skip it\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Detected barcode is:\")\n",
    "    print(\"--------------------\")\n",
    "    print(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joVQt6IKDYZW"
   },
   "outputs": [],
   "source": [
    "def remove_initial_whites(pixels):\n",
    "    # Find the first black pixel\n",
    "    first_black_index = pixels.find('1')\n",
    "    if first_black_index == -1:\n",
    "        return \"\", 0\n",
    "    #return the pixels starting from the first black pixel , first black pixel index\n",
    "    return pixels[first_black_index:] ,first_black_index\n",
    "\n",
    "\n",
    "def make_columns_uniform(image):\n",
    "    #set height , width and number of parts each column will be spilt into\n",
    "    height, width = image.shape\n",
    "    num_parts = 10\n",
    "    part_height = height // num_parts\n",
    "\n",
    "    # Loop through each column\n",
    "    for x in range(width):\n",
    "        part_most_common = []\n",
    "\n",
    "        # Loop through each part of the column\n",
    "        for part in range(num_parts):\n",
    "            # Get the pixels in the part\n",
    "            start_idx = part * part_height\n",
    "            end_idx = (part + 1) * part_height if part != num_parts - 1 else height\n",
    "            part_pixels = image[start_idx:end_idx, x]\n",
    "\n",
    "            # Find most common pixel values in the part (the sorted unique elements of the array and their counts)\n",
    "            unique, counts = np.unique(part_pixels, return_counts=True)\n",
    "\n",
    "            # set common pixels to black (0) or white (255) based on their value\n",
    "            for idx, item in enumerate(unique):\n",
    "                if item >= 128:\n",
    "                    unique[idx] = 255\n",
    "                else:\n",
    "                    unique[idx] = 0\n",
    "            # find most repeated pixel value in the part and append it to the part_most_common list\n",
    "            # so that later we can find the most common column value after looping through all parts\n",
    "            mode_pixel = unique[np.argmax(counts)]\n",
    "            part_most_common.append(mode_pixel)\n",
    "\n",
    "        # Determine the most common value among all the parts\n",
    "        final_unique, final_counts = np.unique(part_most_common, return_counts=True)\n",
    "        most_common_pixel = final_unique[np.argmax(final_counts)]\n",
    "\n",
    "        # Set all pixels in the column to the most common value\n",
    "        image[:, x] = most_common_pixel\n",
    "\n",
    "\n",
    "    return image\n",
    "\n",
    "# This function reorder the corners points appropriatly\n",
    "# Helped significantly with warp function\n",
    "def reorder(myPoints):\n",
    "    myPoints = myPoints.reshape((4, 2))\n",
    "    myPointsNew = np.zeros((4, 1, 2), dtype=np.int32)\n",
    "    add = myPoints.sum(1)\n",
    "    myPointsNew[1] = myPoints[np.argmin(add)]\n",
    "    myPointsNew[3] = myPoints[np.argmax(add)]\n",
    "    diff = np.diff(myPoints, axis=1)\n",
    "    myPointsNew[0] = myPoints[np.argmin(diff)]\n",
    "    myPointsNew[2] = myPoints[np.argmax(diff)]\n",
    "    return myPointsNew\n",
    "\n",
    "def detect_barcode(image):\n",
    "\n",
    "\n",
    "\n",
    "    # blur before sobel\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5),0)\n",
    "    # compute the Scharr gradient magnitude representation of the images in both the x and y direction\n",
    "    gradX = cv2.Sobel(blurred, ddepth = cv2.CV_32F, dx = 1, dy = 0, ksize = -1)\n",
    "    gradY = cv2.Sobel(blurred, ddepth = cv2.CV_32F, dx = 0, dy = 1, ksize = -1)\n",
    "\n",
    "\n",
    "\n",
    "    # subtract the y-gradient from the x-gradient\n",
    "    gradient = cv2.subtract(gradX, gradY)\n",
    "    gradient = cv2.convertScaleAbs(gradient)\n",
    "    # blur and threshold the image\n",
    "    blurred = cv2.blur(gradient, (9, 9))\n",
    "    (_, thresh) = cv2.threshold(blurred, 225, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "    # construct a closing kernel and apply it to the thresholded image\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (21, 7))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # perform a series of erosions and dilations\n",
    "    closed = cv2.erode(closed, None, iterations = 4)\n",
    "\n",
    "    closed = cv2.dilate(closed, None, iterations = 4)\n",
    "\n",
    "    # find the contours in the thresholded image,\n",
    "    #  then sort the contours by their area,\n",
    "    #  keeping only the largest one\n",
    "    (cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "\n",
    "    if cv2.contourArea(cnt) > 0:  # Check if contour is valid\n",
    "\n",
    "        # compute the rotated bounding box of the largest contour\n",
    "        rect = cv2.minAreaRect(cnt)\n",
    "        box = np.int32(cv2.boxPoints(rect))\n",
    "        box = reorder(box)\n",
    "\n",
    "\n",
    "        # Coordinates of each corner\n",
    "        ax = box.item(0)\n",
    "        ay = box.item(1)\n",
    "\n",
    "        bx = box.item(2)\n",
    "        by = box.item(3)\n",
    "\n",
    "        cx = box.item(4)\n",
    "        cy = box.item(5)\n",
    "\n",
    "        dx = box.item(6)\n",
    "        dy = box.item(7)\n",
    "\n",
    "        # find the width and height of the rectangle from the corners\n",
    "        widthA = np.sqrt(((cx - dx) ** 2) + ((cy - dy) ** 2))\n",
    "        widthB = np.sqrt(((ax - bx) ** 2) + ((ay - by) ** 2))\n",
    "        width = max(int(widthA), int(widthB))\n",
    "\n",
    "        heightA = np.sqrt(((ax - dx) ** 2) + ((ay - dy) ** 2))\n",
    "        heightB = np.sqrt(((bx - cx) ** 2) + ((by - cy) ** 2))\n",
    "        height = max(int(heightA), int(heightB))\n",
    "\n",
    "        \n",
    "        pts1 = np.float32([[bx, by], [ax, ay], [cx, cy], [dx, dy]])\n",
    "        pts2 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "        matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "        img_prespective = cv2.warpPerspective(image, matrix, (width, height))\n",
    "\n",
    "        # remove anomalies/remaining noise in the image (set all column pixels to either black or white)\n",
    "        uniform_image = make_columns_uniform(img_prespective)\n",
    "        # save the image to UniformImage.jpg\n",
    "        cv2.imwrite(\"UniformImage.jpg\", uniform_image)\n",
    "        \n",
    "        # read the image to do one last check for possible problems\n",
    "        img = cv2.imread(\"UniformImage.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Get the average of each column in your image\n",
    "        mean = img.mean(axis=0)\n",
    "\n",
    "        # Set it to black or white based on its value\n",
    "        mean[mean <= 127] = 1\n",
    "        mean[mean > 128] = 0\n",
    "\n",
    "        # Convert to string of pixels in order to loop over it\n",
    "        pixels = ''.join(mean.astype(np.uint8).astype(str))\n",
    "        # call the function to remove initial white parts of the barcode\n",
    "        pixels , ignore= remove_initial_whites(pixels)\n",
    "        # after getting the first black pixel, store the image starting from that pixel\n",
    "        image_modified = img[ignore:, ignore:]\n",
    "        # save the image to FinalImage.jpg\n",
    "        cv2.imwrite(\"FinalImage.jpg\", image_modified)\n",
    "        # show the image\n",
    "        plt.imshow(image_modified, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        # call the decoding function\n",
    "        decoded_digits = decode_barcode()\n",
    "        print(decoded_digits)\n",
    "        cv2.waitKey(0)\n",
    "    else:\n",
    "        print(\"No barcode detected\")\n",
    "        cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9f_3q1oEN41"
   },
   "outputs": [],
   "source": [
    "def preprocessing(img , image_path):\n",
    "\n",
    "    avg_intensity =calc_avg_intensity(img)\n",
    "    thresh = apply_dynamic_threshold(img, avg_intensity)\n",
    "    is_salt_pepper =detect_salt_and_pepper_noise(thresh)\n",
    "\n",
    "    if is_salt_pepper:\n",
    "        intensities =plot_time_domain(image_path,300,300)\n",
    "        # Call the function\n",
    "        results = analyze_peaks(intensities, height=150, distance=50, tolerance=5)\n",
    "        peaks_equally_spaced = are_peaks_equally_spaced(intensities,height = 150)\n",
    "        # Output results\n",
    "\n",
    "\n",
    "        if peaks_equally_spaced:\n",
    "            dft_img = np.fft.fft2(img)\n",
    "            if results['filter_type'] == \"High-pass\":\n",
    "                freqimg = try_highpass(dft_img, 20, gaussian=False, keep_dc=True)\n",
    "                # If try_highpass produces complex numbers, extract magnitude\n",
    "                freqimg = np.abs(freqimg)\n",
    "                # Ensure the image is in a uint8 format (0-255) for OpenCV compatibility\n",
    "                freqimg = np.uint8(255 * (freqimg / np.max(freqimg)))  # Normalize to 0-255\n",
    "                # If needed, ensure single-channel image\n",
    "                if len(freqimg.shape) > 2:\n",
    "                    freqimg = cv2.cvtColor(freqimg, cv2.COLOR_BGR2GRAY)\n",
    "                contrast =increase_contrast(freqimg)\n",
    "                detect_barcode(contrast)\n",
    "                plt.imshow(freqimg,cmap='gray')\n",
    "\n",
    "            elif results['filter_type'] == \"Low-pass\":\n",
    "                freqimg = try_lowpass(dft_img, 150, gaussian=True)\n",
    "                # If try_highpass produces complex numbers, extract magnitude\n",
    "                freqimg = np.abs(freqimg)\n",
    "                # Ensure the image is in a uint8 format (0-255) for OpenCV compatibility\n",
    "                # Normalize to 0-255\n",
    "                freqimg = np.uint8(255 * (freqimg / np.max(freqimg)))\n",
    "                # If needed, ensure single-channel image\n",
    "                if len(freqimg.shape) > 2:\n",
    "                    freqimg = cv2.cvtColor(freqimg, cv2.COLOR_BGR2GRAY)\n",
    "                contrast = increase_contrast(freqimg)\n",
    "                detect_barcode(contrast)\n",
    "                plt.imshow(freqimg, cmap='gray')\n",
    "        else:\n",
    "            avg_intensity =calc_avg_intensity(img)\n",
    "            thresholded_image = apply_dynamic_threshold(img,avg_intensity)\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            dil_img = cv2.dilate(thresholded_image, kernel, iterations=1)\n",
    "            erode_img = cv2.erode(dil_img, kernel, iterations=1)\n",
    "\n",
    "            detect_barcode(erode_img)\n",
    "    else:\n",
    "        print(\"No Salt and Pepper Noise\")\n",
    "\n",
    "        avg_intensity =calc_avg_intensity(img)\n",
    "        brightness_threshold = 250\n",
    "\n",
    "        # Check if the image is too bright , as these functions will increase its noise\n",
    "        if avg_intensity < brightness_threshold:\n",
    "            thresholded_image = apply_dynamic_threshold(img,avg_intensity)\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            dil_img = cv2.dilate(thresholded_image, kernel, iterations=1)\n",
    "            erode_img = cv2.erode(dil_img, kernel, iterations=1)\n",
    "            result =increase_contrast(erode_img)\n",
    "            detect_barcode(result)\n",
    "        else:\n",
    "            result =increase_contrast(img)\n",
    "            detect_barcode(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "USNUVEM1ElUL",
    "outputId": "2d41de90-b0aa-4cd6-ed59-94b34064826a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Salt and Pepper Noise\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Detected barcode is:\n",
      "--------------------\n",
      "['Stop/Start', '1', '0', '4', '-', '1', '1', '6', '-', '1', '1', '6', 'Stop/Start']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------MAIN--------------------------------\n",
    "# Uncomment the needed Test Case\n",
    "\n",
    "# image_path ='Test Cases/01 - lol easy.jpg' \n",
    "image_path ='Test Cases/02 - still easy.jpg' \n",
    "# image_path ='Test Cases/03 - eda ya3am ew3a soba3ak mathazarsh.jpg' \n",
    "# image_path ='Test Cases/04 - fen el nadara.jpg' \n",
    "# image_path ='Test Cases/05 - meen taffa el nour!!!.jpg' \n",
    "# image_path ='Test Cases/06 - meen fata7 el nour 333eenaaayy.jpg' \n",
    "# image_path ='Test Cases/07 - mal7 w felfel.jpg' \n",
    "# image_path ='Test Cases/08 - compresso espresso.jpg' \n",
    "# image_path ='Test Cases/09 - e3del el soora ya3ammm.jpg' \n",
    "# image_path ='Test Cases/10 - wen el kontraastttt.jpg' \n",
    "# image_path ='Test Cases/11 - bayza 5ales di bsara7a.jpg' \n",
    "\n",
    "img = cv2.imread(image_path, 0)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# cv2.imshow(\"Original Image\", img)\n",
    "preprocessing(img, image_path)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
