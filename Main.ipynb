{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salah1174/CV-Project/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "3hupx3hHqFxe",
        "outputId": "169e8d1d-0ea2-4332-ad4e-a929170430fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkKAhaEHBWuX"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/drive/MyDrive/CV-Project.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "# --------------------------------------------MAIN--------------------------------------------\n",
        "# Uncomment the needed Test Case\n",
        "\n",
        "# image_path =\"CV-Project/Test Cases/01 - lol easy.jpg\"\n",
        "# image_path =\"Test Cases\\\\02 - still easy.jpg\"\n",
        "# image_path =\"Test Cases\\\\03 - eda ya3am ew3a soba3ak mathazarsh.jpg\"\n",
        "# image_path =\"Test Cases\\\\04 - fen el nadara.jpg\"\n",
        "# image_path =\"Test Cases\\\\05 - meen taffa el nour!!!.jpg\"\n",
        "# image_path =\"Test Cases\\\\06 - meen fata7 el nour 333eenaaayy.jpg\"\n",
        "#image_path =\"07 - mal7 w felfel.jpg\"\n",
        "image_path =\"/content/drive/MyDrive/CV-Project/Test Cases/08 - compresso espresso.jpg\"\n",
        "# image_path =\"CV-Project/Test Cases/09 - e3del el soora ya3ammm.jpg\"\n",
        "# image_path =\"CV-Project/Test Cases/10 - wen el kontraastttt.jpg\"\n",
        "# image_path = \"CV-Project/Test Cases/11 - bayza 5ales di bsara7a.jpg\"\n",
        "\n",
        "img = cv2.imread(image_path, 0)\n",
        "cv2_imshow(img)\n",
        "preprocessing(img, image_path)\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "H3oCqflrCKGX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "36df48a1-e1ac-430b-8195-1346dc130f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'clip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-29a427bdfb6d>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0man\u001b[0m \u001b[0mNxM\u001b[0m \u001b[0mBGRA\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import find_peaks\n",
        "# import BarCodeExtraction\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# --------------------------------------------PREPROCESSOR--------------------------------------------\n",
        "\n",
        "def AdaptiveGaussian(img):\n",
        "    #thresholding\n",
        "    thresh1 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                    cv2.THRESH_BINARY, 31, 5)\n",
        "\n",
        "    thresh2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                    cv2.THRESH_BINARY, 31, 5)\n",
        "\n",
        "    # the window showing output images\n",
        "    # with the corresponding thresholding\n",
        "    # techniques applied to the input image\n",
        "    # cv2_imshow( thresh1)\n",
        "    # cv2_imshow( thresh2)\n",
        "\n",
        "\n",
        "    # De-allocate any associated memory usage\n",
        "    if cv2.waitKey(0) & 0xff == 27:\n",
        "    \tcv2.destroyAllWindows()\n",
        "# from untitled4 import detect_salt_and_pepper_noise\n",
        "# All images passes through this function\n",
        "# If salt and pepper true and freq domain true else false\n",
        "def detect_salt_and_pepper_noise(image, black_threshold=20, white_threshold=80):\n",
        "    total_pixels = image.size\n",
        "    black_pixels = np.sum(image == 0)\n",
        "    white_pixels = np.sum(image == 255)\n",
        "\n",
        "    black_ratio = black_pixels / total_pixels * 100\n",
        "    white_ratio = white_pixels / total_pixels * 100\n",
        "\n",
        "    if black_ratio > black_threshold or white_ratio < white_threshold:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "#if detect_salt_and_pepper_noise is true to determine whether it is salt and pepper(false) or freq domain(true)\n",
        "def plot_time_domain(image_path, row=None, col=None):\n",
        "    \"\"\"\n",
        "    Plots the time-domain representation of pixel intensities from an image.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "        row (int, optional): Row index to extract pixel intensities. If None, the middle row is used.\n",
        "        col (int, optional): Column index to extract pixel intensities. If None, the middle column is used.\n",
        "    \"\"\"\n",
        "    # Load the image in grayscale\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is None:\n",
        "        raise ValueError(\"Image not found or unable to load!\")\n",
        "\n",
        "    # Get image dimensions\n",
        "    rows, cols = image.shape\n",
        "\n",
        "    # Determine which row or column to extract\n",
        "    if row is None and col is None:\n",
        "        row = rows // 2  # Default to the middle row\n",
        "    elif row is not None and (row < 0 or row >= rows):\n",
        "        raise ValueError(f\"Row index out of bounds. Must be between 0 and {rows - 1}.\")\n",
        "    elif col is not None and (col < 0 or col >= cols):\n",
        "        raise ValueError(f\"Column index out of bounds. Must be between 0 and {cols - 1}.\")\n",
        "\n",
        "    # Extract the pixel intensities\n",
        "    if row is not None:\n",
        "        intensities = image[row, :]  # Pixel intensities from the row\n",
        "        x = np.arange(cols)  # X-axis: column indices\n",
        "        label = f\"Row {row}\"\n",
        "    else:\n",
        "        intensities = image[:, col]  # Pixel intensities from the column\n",
        "        x = np.arange(rows)  # X-axis: row indices\n",
        "        label = f\"Column {col}\"\n",
        "\n",
        "    # Plot the time-domain representation\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(x, intensities, label=label, color='b')\n",
        "    plt.title(f\"Time-Domain Representation of {label}\")\n",
        "    plt.xlabel(\"Pixel Index\")\n",
        "    plt.ylabel(\"Pixel Intensity\")\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return intensities\n",
        "\n",
        "\n",
        "def analyze_peaks(signal, height=None, distance=50, tolerance=5, sampling_rate=1.0, plot=True):\n",
        "    \"\"\"\n",
        "    Analyzes peaks in the time-domain signal and computes frequency domain characteristics.\n",
        "    Returns the filter type based on the detected dominant frequencies.\n",
        "    \"\"\"\n",
        "    # Dynamically adjust height if not provided\n",
        "    if height is None:\n",
        "        height = np.mean(signal) + 0.5 * np.std(signal)\n",
        "\n",
        "    # Detect peaks\n",
        "    peaks, _ = find_peaks(signal, height=height, distance=distance)\n",
        "\n",
        "    if len(peaks) == 0:\n",
        "        print(\n",
        "            \"No peaks detected. Consider adjusting the 'height' or 'distance' parameters.\")\n",
        "        return {\n",
        "            'peaks': [],\n",
        "            'peak_distances': [],\n",
        "            'are_distances_equal': False,\n",
        "            'dominant_frequencies': [],\n",
        "            'magnitudes': [],\n",
        "            'filter_type': None  # No filter type if no peaks are detected\n",
        "        }\n",
        "\n",
        "    # Calculate peak distances\n",
        "    peak_distances = np.diff(peaks)\n",
        "    if len(peak_distances) > 0:\n",
        "        are_distances_equal = np.allclose(peak_distances, peak_distances[0], atol=tolerance)\n",
        "    else:\n",
        "        are_distances_equal = False\n",
        "\n",
        "    # Compute FFT\n",
        "    fft_result = np.fft.fft(signal)\n",
        "    fft_magnitude = np.abs(fft_result)\n",
        "    fft_frequencies = np.fft.fftfreq(len(signal), d=1/sampling_rate)\n",
        "\n",
        "    # Consider positive frequencies\n",
        "    positive_frequencies = fft_frequencies[:len(signal)//2]\n",
        "    positive_magnitude = fft_magnitude[:len(signal)//2]\n",
        "\n",
        "    # Detect peaks in FFT magnitude\n",
        "    fft_peaks, _ = find_peaks(\n",
        "        positive_magnitude, height=np.mean(positive_magnitude))\n",
        "    dominant_frequencies = positive_frequencies[fft_peaks]\n",
        "    dominant_magnitudes = positive_magnitude[fft_peaks]\n",
        "\n",
        "    # Print the detected dominant frequencies and their magnitudes\n",
        "    print(\"Detected Dominant Frequencies (Hz):\", dominant_frequencies * 10000)\n",
        "    print(\"Corresponding Magnitudes:\", dominant_magnitudes)\n",
        "\n",
        "    filter_type = None  # Default filter type is None\n",
        "\n",
        "    # Determine the filter type based on the dominant frequencies\n",
        "    if dominant_frequencies.size > 0:\n",
        "        if dominant_frequencies[0] * 10000 < 60:\n",
        "            filter_type = \"Low-pass\"\n",
        "            print(\"Low Frequency: Low-pass filter likely used.\")\n",
        "        else:\n",
        "            filter_type = \"High-pass\"\n",
        "            print(\"High Frequency: High-pass filter likely used.\")\n",
        "    else:\n",
        "        filter_type = \"Low-pass\"  # Default to low-pass if no dominant frequencies\n",
        "\n",
        "    # Plot the signal and frequency domain if requested\n",
        "    if plot:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Plot time-domain signal\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(signal, label='Signal')\n",
        "        plt.plot(peaks, signal[peaks], 'ro', label='Detected Peaks')\n",
        "        plt.title('Time-Domain Signal with Peaks')\n",
        "        plt.xlabel('Sample Index')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "\n",
        "        # Plot frequency-domain\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(positive_frequencies, positive_magnitude,\n",
        "                 label='FFT Magnitude')\n",
        "        plt.plot(dominant_frequencies, dominant_magnitudes,\n",
        "                 'ro', label='Dominant Frequencies')\n",
        "        plt.title('Frequency-Domain Analysis')\n",
        "        plt.xlabel('Frequency (Hz)')\n",
        "        plt.ylabel('Magnitude')\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Return analysis results including the filter type\n",
        "    return {\n",
        "        'peaks': peaks,\n",
        "        'peak_distances': peak_distances,\n",
        "        'are_distances_equal': are_distances_equal,\n",
        "        'dominant_frequencies': dominant_frequencies,\n",
        "        'magnitudes': dominant_magnitudes,\n",
        "        'filter_type': filter_type\n",
        "    }\n",
        "\n",
        "\n",
        "def are_peaks_equally_spaced(signal, height=None, distance=50, tolerance=5):\n",
        "    \"\"\"\n",
        "    Checks if the spaces (differences) between peaks in the given signal are approximately equal.\n",
        "\n",
        "    Parameters:\n",
        "        signal (numpy array): The input time-domain signal (1D array).\n",
        "        height (float): Minimum height for a point to be considered a peak. Default is 150.\n",
        "        distance (int): Minimum distance between consecutive peaks. Default is 50.\n",
        "        tolerance (int): Allowed deviation for equal distances. Default is 5.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the differences between consecutive peaks are approximately equal, False otherwise.\n",
        "    \"\"\"\n",
        "    # Detect peaks\n",
        "    peaks, _ = find_peaks(signal, height=height, distance=distance)\n",
        "\n",
        "    # Calculate peak distances\n",
        "    peak_distances = np.diff(peaks)\n",
        "\n",
        "    # Check if all distances are approximately equal\n",
        "    if len(peak_distances) > 0:\n",
        "        return np.allclose(peak_distances, peak_distances[0], atol=tolerance)\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# if are_peaks_equally_spaced returns true\n",
        "def try_highpass(dft_img, limit, gaussian: bool = False, keep_dc: bool = False):\n",
        "    mask = ~give_me_circle_mask_nowww(dft_img.shape, limit)\n",
        "    if (gaussian):\n",
        "        mask = cv2.GaussianBlur(mask, (21, 21), 0)\n",
        "    if (keep_dc):\n",
        "        mask[dft_img.shape[0]//2, dft_img.shape[1]//2] = 255\n",
        "    dft_img_shifted = np.fft.fftshift(dft_img)\n",
        "    dft_img_shifted_highpass = np.multiply(dft_img_shifted, mask)\n",
        "    freqimg = plot_shifted_fft_and_ifft(dft_img_shifted_highpass)\n",
        "    return freqimg\n",
        "\n",
        "\n",
        "def try_lowpass(dft_img, limit, gaussian: bool = False):\n",
        "    mask = give_me_circle_mask_nowww(dft_img.shape, limit)\n",
        "    if (gaussian):\n",
        "        mask = cv2.GaussianBlur(mask, (21, 21), 0)\n",
        "    dft_img_shifted = np.fft.fftshift(dft_img)\n",
        "    dft_img_shifted_lowpass = np.multiply(dft_img_shifted, mask)\n",
        "    freqimg = plot_shifted_fft_and_ifft(dft_img_shifted_lowpass)\n",
        "    return freqimg\n",
        "\n",
        "def sharpen_image(image):\n",
        "    # Define the sharpening kernel\n",
        "    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
        "\n",
        "    # Apply the sharpening filter\n",
        "    sharpened = cv2.filter2D(image, -1, kernel)\n",
        "\n",
        "    return sharpened\n",
        "\n",
        "def enhance_barcode(image):\n",
        "    sharpened_image = sharpen_image(image)\n",
        "\n",
        "    return sharpened_image\n",
        "\n",
        "def give_me_circle_mask_nowww(mask_size, radius):\n",
        "    mask = np.zeros(mask_size)\n",
        "    cy = mask.shape[0] // 2\n",
        "    cx = mask.shape[1] // 2\n",
        "    return cv2.circle(mask, (cx, cy), radius, (255, 255, 255), -1).astype(np.uint8)\n",
        "\n",
        "def plot_shifted_fft_and_ifft(dft_img_shifted):\n",
        "    img = np.fft.ifft2(np.fft.ifftshift(dft_img_shifted))\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(10, 5), nrows=1, ncols=2)\n",
        "    ax1.set(yticks=[0, img.shape[0]//2, img.shape[0] - 1],\n",
        "            yticklabels=[-img.shape[0]//2, 0, img.shape[0]//2 - 1])\n",
        "    ax1.set(xticks=[0, img.shape[1]//2, img.shape[1] - 1],\n",
        "            xticklabels=[-img.shape[1]//2, 0, img.shape[1]//2 - 1])\n",
        "    # ax1.imshow(np.abs(dft_img_shifted)**0.1, cmap='gray')\n",
        "    # ax2.imshow(np.abs(img), cmap='gray')\n",
        "\n",
        "    # img = np.abs(img.astype(np.uint16))\n",
        "    img = np.abs(img)  # Get magnitude\n",
        "    img = img.astype(np.uint16)\n",
        "    # plt.imsave(\"AX2.jpg\",img)\n",
        "    # img = cv2.imread(\"AX2.jpg\")\n",
        "    # cv2_imshow(\"AX2\", img)\n",
        "    # ax2 = ax2.astype(np.uint32)\n",
        "    # ax2.imsave(\"Test Cases\\\\11 - bayza 5ales di bsara7a#3.jpg\", np.abs(img), p)\n",
        "    # plt.show()\n",
        "    return img\n",
        "\n",
        "# This is what im gonna use **********************************\n",
        "# increase <20 w >220\n",
        "def increase_contrast(image):\n",
        "    # Apply linear contrast stretching\n",
        "    min_val, max_val = np.min(image), np.max(image)\n",
        "    contrast_image = (image - min_val) * (255 / (max_val - min_val))\n",
        "    contrast_image = np.uint8(contrast_image)  # Convert back to uint8 type\n",
        "\n",
        "    return contrast_image\n",
        "\n",
        "def calc_avg_intensity(image):\n",
        "    return np.mean(image)\n",
        "\n",
        "def apply_dynamic_threshold(image, avg_intensity):\n",
        "    if (avg_intensity>120 and avg_intensity<130 ): #check if gray compressed (only one that causes issues with threshold is gray compressed)\n",
        "      image = increase_contrast(image)\n",
        "      avg_intensity = calc_avg_intensity(image)\n",
        "\n",
        "    threshold_value = int(avg_intensity * 0.75)\n",
        "    _, thresholded_image = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "    return thresholded_image\n",
        "def applydynamic_threshold(image, avg_intensity):\n",
        "   #check if gray compressed (only one that causes issues with threshold is gray compressed)\n",
        "    if (avg_intensity>120 and avg_intensity<130 ):\n",
        "      image = increase_contrast(image)\n",
        "      avg_intensity = calc_avg_intensity(image)\n",
        "\n",
        "    threshold_value = int(avg_intensity * 0.75)\n",
        "    _, thresholded_image = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "    return thresholded_image\n",
        "\n",
        "def preprocessing(img , image_path):\n",
        "\n",
        "    avg_intensity =calc_avg_intensity(img)\n",
        "    thresh = applydynamic_threshold(img,avg_intensity)\n",
        "    is_salt_pepper =detect_salt_and_pepper_noise(thresh)\n",
        "\n",
        "    print(img.shape)\n",
        "    print(is_salt_pepper)\n",
        "    if is_salt_pepper:\n",
        "        intensities =plot_time_domain(image_path,300,300)\n",
        "        print(is_salt_pepper)\n",
        "        # Call the function\n",
        "        results = analyze_peaks(intensities, height=150, distance=50, tolerance=5)\n",
        "        peaks_equally_spaced = are_peaks_equally_spaced(intensities,height = 150)\n",
        "        # Output results\n",
        "        print(\"Peak indices:\", results['peaks'])\n",
        "        print(\"Peak distances:\", results['peak_distances'])\n",
        "        print(\"Are distances approximately equal?\", results['are_distances_equal'])\n",
        "\n",
        "\n",
        "        if peaks_equally_spaced:\n",
        "            # avg_int2 = calc_avg_intensity(img)\n",
        "            dft_img = np.fft.fft2(img)\n",
        "            # dft_img_shift = np.fft.fftshift(dft_img)\n",
        "            if results['filter_type'] == \"High-pass\":\n",
        "                freqimg = try_highpass(dft_img, 20, gaussian=False, keep_dc=True)\n",
        "                # If try_highpass produces complex numbers, extract magnitude\n",
        "                freqimg = np.abs(freqimg)\n",
        "                # Ensure the image is in a uint8 format (0-255) for OpenCV compatibility\n",
        "                freqimg = np.uint8(255 * (freqimg / np.max(freqimg)))  # Normalize to 0-255\n",
        "                # If needed, ensure single-channel image\n",
        "                if len(freqimg.shape) > 2:\n",
        "                    freqimg = cv2.cvtColor(freqimg, cv2.COLOR_BGR2GRAY)\n",
        "                contrast =increase_contrast(freqimg)\n",
        "                cv2_imshow( freqimg)\n",
        "                detect_barcode(contrast)\n",
        "\n",
        "\n",
        "            elif results['filter_type'] == \"Low-pass\":\n",
        "                freqimg = try_lowpass(dft_img, 150, gaussian=True)\n",
        "                # If try_highpass produces complex numbers, extract magnitude\n",
        "                freqimg = np.abs(freqimg)\n",
        "                # Ensure the image is in a uint8 format (0-255) for OpenCV compatibility\n",
        "                # Normalize to 0-255\n",
        "                freqimg = np.uint8(255 * (freqimg / np.max(freqimg)))\n",
        "                # If needed, ensure single-channel image\n",
        "                if len(freqimg.shape) > 2:\n",
        "                    freqimg = cv2.cvtColor(freqimg, cv2.COLOR_BGR2GRAY)\n",
        "                contrast = increase_contrast(freqimg)\n",
        "                cv2_imshow( freqimg)\n",
        "                detect_barcode(contrast)\n",
        "\n",
        "        else:\n",
        "            avg_intensity =calc_avg_intensity(img)\n",
        "            thresholded_image = apply_dynamic_threshold(img,avg_intensity)\n",
        "            # cv2_imshow(\"Thresholded Image\", thresholded_image)\n",
        "            kernel = np.ones((3, 3), np.uint8)\n",
        "            dil_img = cv2.dilate(thresholded_image, kernel, iterations=1)\n",
        "            erode_img = cv2.erode(dil_img, kernel, iterations=1)\n",
        "\n",
        "            # cv2_imshow(\"Dilated Image\", erode_img)\n",
        "            detect_barcode(erode_img)\n",
        "    else:\n",
        "        print(\"No Salt and Pepper Noise\")\n",
        "\n",
        "        avg_intensity =calc_avg_intensity(img)\n",
        "        brightness_threshold = 250\n",
        "\n",
        "        if avg_intensity < brightness_threshold:\n",
        "            thresholded_image = apply_dynamic_threshold(img,avg_intensity)\n",
        "            # cv2_imshow(\"Thresholded Image\", thresholded_image)\n",
        "            kernel = np.ones((3, 3), np.uint8)\n",
        "            dil_img = cv2.dilate(thresholded_image, kernel, iterations=1)\n",
        "            erode_img = cv2.erode(dil_img, kernel, iterations=1)\n",
        "            result =increase_contrast(erode_img)\n",
        "            detect_barcode(result)\n",
        "        else:\n",
        "            result =increase_contrast(img)\n",
        "            detect_barcode(result)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kyh-6Iq9DNAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "xKwCnXRbgD5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "# --------------------------------------------BAR CODE EXTRACTION--------------------------------------------\n",
        "\n",
        "# import Decoder\n",
        "def remove_initial_whites(pixels):\n",
        "    first_black_index = pixels.find('1')\n",
        "    if first_black_index == -1:\n",
        "        return \"\", 0\n",
        "    return pixels[first_black_index:] ,first_black_index\n",
        "\n",
        "\n",
        "def make_columns_uniform(image):\n",
        "    height, width = image.shape\n",
        "    num_parts = 10\n",
        "    part_height = height // num_parts\n",
        "\n",
        "    for x in range(width):\n",
        "        part_most_common = []\n",
        "\n",
        "        for part in range(num_parts):\n",
        "            start_idx = part * part_height\n",
        "            end_idx = (part + 1) * part_height if part != num_parts - 1 else height\n",
        "            part_pixels = image[start_idx:end_idx, x]\n",
        "\n",
        "            # Find  most common pixel value in the part\n",
        "            unique, counts = np.unique(part_pixels, return_counts=True)\n",
        "\n",
        "            for idx, item in enumerate(unique):\n",
        "                if item >= 128:\n",
        "                    unique[idx] = 255\n",
        "                else:\n",
        "                    unique[idx] = 0\n",
        "\n",
        "            mode_pixel = unique[np.argmax(counts)]\n",
        "            part_most_common.append(mode_pixel)\n",
        "\n",
        "        # Determine the most common value among the parts\n",
        "        final_unique, final_counts = np.unique(part_most_common, return_counts=True)\n",
        "        most_common_pixel = final_unique[np.argmax(final_counts)]\n",
        "\n",
        "        # Set all pixels in the column to the most common value\n",
        "        image[:, x] = most_common_pixel\n",
        "\n",
        "\n",
        "    return image\n",
        "\n",
        "# This function reorder the corners points appropriatly\n",
        "# Helped significantly with warp function\n",
        "def reorder(myPoints):\n",
        "    myPoints = myPoints.reshape((4, 2))\n",
        "    myPointsNew = np.zeros((4, 1, 2), dtype=np.int32)\n",
        "    add = myPoints.sum(1)\n",
        "    myPointsNew[1] = myPoints[np.argmin(add)]\n",
        "    myPointsNew[3] = myPoints[np.argmax(add)]\n",
        "    diff = np.diff(myPoints, axis=1)\n",
        "    myPointsNew[0] = myPoints[np.argmin(diff)]\n",
        "    myPointsNew[2] = myPoints[np.argmax(diff)]\n",
        "    return myPointsNew\n",
        "\n",
        "def detect_barcode(image):\n",
        "\n",
        "    # 1---->canny\n",
        "\n",
        "    # blurred = cv2.GaussianBlur(image, (9, 9), 0)\n",
        "    # edges = cv2.Canny(image, 50, 150)\n",
        "    # blurred = cv2.blur(edges, (9, 9))\n",
        "    # _, thresh = cv2.threshold(blurred, 50, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    #2---->blur before sobel\n",
        "    blurred = cv2.GaussianBlur(image, (5, 5),0)\n",
        "    # compute the Scharr gradient magnitude representation of the images in both the x and y direction\n",
        "    gradX = cv2.Sobel(blurred, ddepth = cv2.CV_32F, dx = 1, dy = 0, ksize = -1)\n",
        "    gradY = cv2.Sobel(blurred, ddepth = cv2.CV_32F, dx = 0, dy = 1, ksize = -1)\n",
        "\n",
        "    #3---->sobel\n",
        "\n",
        "    # # compute the Scharr gradient magnitude representation of the images in both the x and y direction\n",
        "    # gradX = cv2.Sobel(image, ddepth = cv2.CV_32F, dx = 1, dy = 0, ksize = -1)\n",
        "    # gradY = cv2.Sobel(image, ddepth = cv2.CV_32F, dx = 0, dy = 1, ksize = -1)\n",
        "\n",
        "    # for gradient 2, 3 only:\n",
        "\n",
        "    # subtract the y-gradient from the x-gradient\n",
        "    gradient = cv2.subtract(gradX, gradY)\n",
        "    gradient = cv2.convertScaleAbs(gradient)\n",
        "    # blur and threshold the image\n",
        "    blurred = cv2.blur(gradient, (9, 9))\n",
        "    (_, thresh) = cv2.threshold(blurred, 225, 255, cv2.THRESH_BINARY)\n",
        "    # cv2_imshow(\"thresholded\",thresh)\n",
        "\n",
        "\n",
        "    # construct a closing kernel and apply it to the thresholded image\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (21, 7))\n",
        "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # perform a series of erosions and dilations\n",
        "    # cv2_imshow('closed1', closed)\n",
        "    closed = cv2.erode(closed, None, iterations = 4)\n",
        "\n",
        "    closed = cv2.dilate(closed, None, iterations = 4)\n",
        "\n",
        "    # find the contours in the thresholded image,\n",
        "    #  then sort the contours by their area,\n",
        "    #  keeping only the largest one\n",
        "    (cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
        "\n",
        "    if cv2.contourArea(cnt) > 0:  # Check if contour is valid\n",
        "\n",
        "        # compute the rotated bounding box of the largest contour\n",
        "        rect = cv2.minAreaRect(cnt)\n",
        "        box = np.int32(cv2.boxPoints(rect))\n",
        "        box = reorder(box)\n",
        "\n",
        "\n",
        "        # Coordinates of each corner\n",
        "        ax = box.item(0)\n",
        "        ay = box.item(1)\n",
        "\n",
        "        bx = box.item(2)\n",
        "        by = box.item(3)\n",
        "\n",
        "        cx = box.item(4)\n",
        "        cy = box.item(5)\n",
        "\n",
        "        dx = box.item(6)\n",
        "        dy = box.item(7)\n",
        "\n",
        "        # box coordinates\n",
        "        # x, y, w, h = cv2.boundingRect(box)\n",
        "\n",
        "        # print(box)\n",
        "        # border_threshold = 10\n",
        "        # height, width = image.shape[:2]\n",
        "\n",
        "        widthA = np.sqrt(((cx - dx) ** 2) + ((cy - dy) ** 2))\n",
        "        widthB = np.sqrt(((ax - bx) ** 2) + ((ay - by) ** 2))\n",
        "        width = max(int(widthA), int(widthB))\n",
        "\n",
        "        heightA = np.sqrt(((ax - dx) ** 2) + ((ay - dy) ** 2))\n",
        "        heightB = np.sqrt(((bx - cx) ** 2) + ((by - cy) ** 2))\n",
        "        height = max(int(heightA), int(heightB))\n",
        "\n",
        "        # Draw the extended bounding box\n",
        "        # cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
        "\n",
        "        # Crop the barcode\n",
        "        # cropped_barcode = image[y:y+height, x:x+width]\n",
        "\n",
        "\n",
        "        pts1 = np.float32([[bx, by], [ax, ay], [cx, cy], [dx, dy]])\n",
        "        pts2 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
        "\n",
        "        matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "        img_prespective = cv2.warpPerspective(image, matrix, (width, height))\n",
        "\n",
        "\n",
        "\n",
        "        # cv2_imshow('Gradient', gradient)\n",
        "        # cv2_imshow('Blurred', blurred)\n",
        "        # cv2_imshow('closed2', closed)\n",
        "        # cv2_imshow(\"Image\", image)\n",
        "        # cv2_imshow('Cropped Barcode', cropped_barcode)\n",
        "        # cv2_imshow(\"Warp\", img_prespective)\n",
        "        # cv2_imshow(\"Original\", image)\n",
        "        uniform_image = make_columns_uniform(img_prespective)\n",
        "        # cv2_imshow(\"Uniform Image\", uniform_image)\n",
        "        cv2.imwrite(\"UniformImage.jpg\", uniform_image)\n",
        "\n",
        "        #remove extra white space\n",
        "        img = cv2.imread(\"UniformImage.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "        # Get the average of each column in your image\n",
        "        mean = img.mean(axis=0)\n",
        "        # print(mean)\n",
        "        # Set it to black or white based on its value\n",
        "        mean[mean <= 127] = 1\n",
        "        mean[mean > 128] = 0\n",
        "        # Convert to string of pixels in order to loop over it\n",
        "        pixels = ''.join(mean.astype(np.uint8).astype(str))\n",
        "        pixels , ignore= remove_initial_whites(pixels)\n",
        "        image_modified = img[ignore:, ignore:]\n",
        "\n",
        "        #save image\n",
        "        cv2.imwrite(\"FinalImage.jpg\", image_modified)\n",
        "        # show image\n",
        "        cv2_imshow( image_modified)\n",
        "        # call decoding function then print decoded digits\n",
        "        decode_barcode()\n",
        "\n",
        "        cv2.waitKey(0)\n",
        "    else:\n",
        "        print(\"No barcode detected\")\n",
        "        cv2.waitKey(0)\n"
      ],
      "metadata": {
        "id": "vSC4JpXADVaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "# --------------------------------------------DECODER--------------------------------------------\n",
        "\n",
        "def detect_and_normalize_bar_sizes(pixels, narrow_bar_size, wide_bar_size,):\n",
        "    bar_widths = []\n",
        "    current_width = 1\n",
        "    current_pixel = pixels[0]\n",
        "\n",
        "    for pixel in pixels[1:]:\n",
        "        if pixel == current_pixel:\n",
        "            current_width += 1\n",
        "            # print(f\"current pixel is : {current_pixel}\")\n",
        "        else:\n",
        "            bar_widths.append((current_pixel, current_width))\n",
        "            # print(f\"current width is : {current_width}\")\n",
        "            current_width = 1\n",
        "            current_pixel = pixel\n",
        "\n",
        "    if current_width > 0:\n",
        "        bar_widths.append((current_pixel, current_width))\n",
        "\n",
        "    # narrow_bar_size = min(width for _, width in bar_widths)\n",
        "    # wide_bar_size = 2* narrow_bar_size\n",
        "    # max_bar_size = max(width for _, width in bar_widths if width > narrow_bar_size)\n",
        "    average = sum(width for _, width in bar_widths) / len(bar_widths)\n",
        "    # print(f\"average is {average}\")\n",
        "    normalized_pixels = []\n",
        "\n",
        "    for pixel, width in bar_widths:\n",
        "        if width <= narrow_bar_size:\n",
        "            normalized_pixels.append((pixel, narrow_bar_size))\n",
        "        elif width > narrow_bar_size:\n",
        "            if width <= average:\n",
        "                normalized_pixels.append((pixel, narrow_bar_size))\n",
        "            elif average < width :\n",
        "                    normalized_pixels.extend([(pixel, wide_bar_size)])\n",
        "            else:\n",
        "                print(\"Invalid barcode\")\n",
        "                break\n",
        "        else:\n",
        "            print(\"Invalid barcode\")\n",
        "            break\n",
        "\n",
        "    normalized_pixel_str = ''.join(\n",
        "        ('1' * width) if pixel == '1' else ('0' * width) for pixel, width in normalized_pixels)\n",
        "\n",
        "    return normalized_pixel_str\n",
        "\n",
        "\n",
        "def decode_barcode():\n",
        "    # 0 means narrow, 1 means wide\n",
        "    NARROW = \"0\"\n",
        "    WIDE = \"1\"\n",
        "    code11_widths = {\n",
        "        \"00110\": \"Stop/Start\",\n",
        "        \"10001\": \"1\",\n",
        "        \"01001\": \"2\",\n",
        "        \"11000\": \"3\",\n",
        "        \"00101\": \"4\",\n",
        "        \"10100\": \"5\",\n",
        "        \"01100\": \"6\",\n",
        "        \"00011\": \"7\",\n",
        "        \"10010\": \"8\",\n",
        "        \"10000\": \"9\",\n",
        "        \"00001\": \"0\",\n",
        "        \"00100\": \"-\",\n",
        "    }\n",
        "    img = cv.imread(\"FinalImage.jpg\", cv.IMREAD_GRAYSCALE)\n",
        "    # Get the average of each column in your image\n",
        "    mean = img.mean(axis=0)\n",
        "    # print(mean)\n",
        "    # Set it to black or white based on its value\n",
        "    mean[mean <= 127] = 1\n",
        "    mean[mean > 128] = 0\n",
        "    # Convert to string of pixels in order to loop over it\n",
        "    pixels = ''.join(mean.astype(np.uint8).astype(str))\n",
        "    # print(pixels)\n",
        "\n",
        "    # Need to figure out how many pixels represent a narrow bar\n",
        "    narrow_bar_size = 0\n",
        "    for pixel in pixels:\n",
        "        if pixel == \"1\":\n",
        "            narrow_bar_size += 1\n",
        "            # print(narrow_bar_size)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    wide_bar_size = narrow_bar_size * 2\n",
        "\n",
        "    # print(f\"Detected narrow bar size: {narrow_bar_size}\")\n",
        "    # print(f\"Detected wide bar size: {wide_bar_size}\")\n",
        "\n",
        "    pixels = detect_and_normalize_bar_sizes(pixels, narrow_bar_size, wide_bar_size)\n",
        "    # print(f\"Detected pixels: {pixels}\")\n",
        "\n",
        "    digits = []\n",
        "    pixel_index = 0\n",
        "    current_digit_widths = \"\"\n",
        "    skip_next = False\n",
        "    while pixel_index < len(pixels):\n",
        "\n",
        "        if skip_next:\n",
        "            pixel_index += narrow_bar_size\n",
        "            skip_next = False\n",
        "            continue\n",
        "        count = 1\n",
        "        try:                                                      # 1 1 1 1 0 0 0 0 1 1 1  1  1  1  1  1\n",
        "            while pixels[pixel_index] == pixels[pixel_index + 1]: # 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
        "                count += 1\n",
        "                pixel_index += 1\n",
        "        except:\n",
        "            pass\n",
        "        pixel_index += 1\n",
        "        current_digit_widths += NARROW if count == narrow_bar_size else WIDE\n",
        "        # print(current_digit_widths)\n",
        "        if current_digit_widths in code11_widths:\n",
        "            digits.append(code11_widths[current_digit_widths])\n",
        "            current_digit_widths = \"\"\n",
        "            skip_next = True  # Next iteration will be a separator, so skip it\n",
        "    print(\"-------------------------------------------------------\")\n",
        "    print(\"-------------------------------------------------------\")\n",
        "    print(\"Detected barcode is:\")\n",
        "    print(\"--------------------\")\n",
        "    print(\"--------------------\")\n",
        "    print(digits)"
      ],
      "metadata": {
        "id": "P90156fYDZE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}